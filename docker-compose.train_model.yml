services:
  # Main training service
  reasoning-models:
    build:
      context: .
      dockerfile: src/training_pipeline/Dockerfile
    container_name: reasoning-models-training
    
    volumes:
      # Mount the entire project directory
      - .:/workspace
      # Mount a persistent volume for outputs
      - ./output:/workspace/output
      # Mount text cache
      - ./text_cache:/workspace/text_cache
    
    working_dir: /workspace
    
    # Run the training script
    command: python src/training_pipeline/train_model.py
    
    environment:
      - PYTHONPATH=/workspace/src
      - CUDA_VISIBLE_DEVICES=0
    
    # Restart policy - only restart if there's a failure
    restart: "no"
